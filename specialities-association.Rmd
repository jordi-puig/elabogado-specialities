---
title: 'elAbogado - Specialities Association'
author: "Autor: Jordi Puig"
date: "Gener 2022"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: header.html
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
******
# Introducció
******
## Presentació
Aquest estudi tracta de trobar una relació entre les especialitats escollides entre el advocats de la plataforma per tal de suggerir a partir dels patrons proposats per els propis usuaris de la plataforma. 

El primer que fem es carregar les llibreries que es necessiten


```{r message= FALSE, warning=FALSE}
library(cluster)
library(dplyr)
library(class)
library(purrr)
library(ggplot2)
library(factoextra)
library(mclust)
library(arules)
```

******
# Exercici
******

## Estudi previ i preparació de les dades

```{r message= FALSE, warning=FALSE}

# carreguem les dades i strings els factoritzem 
specialities.data<-read.csv('specialities-all.csv',stringsAsFactors = FALSE, encoding='latin1')

# veiem el nombre de registres que tenim
str(dim(specialities.data)[1])

# veiem l'estructura de les dades
str(specialities.data)

summary(specialities.data)

```

El conjunt de les dades es composa de 66755 registres amb 4 columnes:

* id_user: es un enter que identifica al usuari
* locality: cadena de chars que identifica la localitat de l'usuari
* speciality: cadena de chars que identifica la especialitat de l'usuari


### Tractament de valors buits
```{r message= FALSE, warning=FALSE}
colSums(is.na(specialities.data))
```


No tenim valors buits, per tant no hem de tractar aquests valors.


### Discretitzem les dades i les carreguem com a transaccions
```{r message= FALSE, warning=FALSE}
# discretitzem les dades 
for (i in 1:3) {
  specialities.data[,i] <- as.factor(specialities.data[,i])
}

summary(specialities.data)
```

### Estudi de la repetició del camp speciality
```{r message= FALSE, warning=FALSE}

# transformem el data en una llista de les specialities agrupats per els usuaris, es a dir, tenim les specialities que escull cada usuari

# contem el número d'usuaris diferents i ens surten 15000. Tindrem 12130 transaccions
users <- specialities.data[,"id_user"]
n_distinct(users)

speciality <- split(x=specialities.data[,"speciality"],f=specialities.data$id_user)

# trasformem el data com a transactions. Cada transacció es un usuari i les espcialitats que selecciona
speciality.transactions <- as(speciality,"transactions")

itemFrequencyPlot(speciality.transactions, support = .1, cex.names = .6, col = rainbow(10), topN=10)
```


Mostrem les especialitats que més es repeteixen. En concret estem mostrant aquells que tenen un suport o freqüencia >= 0.1. Si tenim 15000 transaccions, estem mostrant x >= 15.000 * 0.1, es a dir aquells que apareixen com a mínim 1050 vegades.

Les especialitats que més és repeteixes són: Divorcios, Civil, Familia, Penal...

## Aplicació d'algoritme apriori 
Si llancem l'algoritme "apriori", generarem directament un set de regles amb diferent suport, confiança i lift. 

* El *support* indica quantes vegades s'han trovat les regles {lsh => rhs} en el dataset, com més alt millor. Es la "popularitat" d'un conjunt d'elements del dataset. On {lsh => rhs} indica que si selecciones lsh, seleccionen rhs.

* La *confidence* ens parla de la probabilitat que seleccionin {rhs} si seleccionan {lhs} (lhs => rhs / lhs).

* El *lift* és un paràmetre que ens indica quan d'aletorietat hi ha a les regles. Un lift de 1 o menys ens indica que la regla és completament fruit de l'atzar. El lift ens diu en una regla, com es produeix la regla en funció dels elements de la regla (support(lhs => rhs) / support(lhs) * support(rhs)).

Generem les regles per un support mínim de 0.25 i confidence mínim de 0.4

```{r message= FALSE, warning=FALSE}
rules <- apriori(speciality.transactions, parameter = list(support = 0.25, confidence = 0.4))

inspect(head(sort(rules, by = "support"), 100))
```

Amb aquesta ordenació per *confidence*, tenim una probabilitat alta que si tenen Familia tenen Divorcios. Es un exemple, el mateix passa amb la resta de les mostrades. En tots els casos el lift es molt superior a 1, per tant considerem que no hi ha aletorietat en els resultats.

Aquestes regles tenen a més una probabilitat condicionada (confidence) relativament alta  > 40%

Podem generar altres regles que impliquin un mínim de dos elements del lhs. Hem de reduïr el support i el confidence.

```{r message= FALSE, warning=FALSE}

rules2 <- apriori(speciality.transactions, parameter = list(support = 0.01, confidence = 0.1, minlen=2))

inspect(head(sort(rules2, by = "support"), 100))
```